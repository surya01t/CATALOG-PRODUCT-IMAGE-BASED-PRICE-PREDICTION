{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slYHkEYsQhDq",
        "outputId": "47397fea-77b5-41ac-e651-4cd8943a32fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Device: cuda\n",
            "Rows: 75000\n",
            "Train=60000 | Valid=15000 | Clip=[0.63,329.99]\n"
          ]
        }
      ],
      "source": [
        "# ================================================================\n",
        "# ONE-CELL: MiniLM (Text) + Swin-Tiny (Vision) → MLP\n",
        "# Predict Product Price (train + eval + artifact save)\n",
        "# Compact, Colab-ready, GPU-optimized\n",
        "# ================================================================\n",
        "!pip -q install torch torchvision torchaudio transformers pandas scikit-learn pillow tqdm --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "import os, io, re, json, time, random, hashlib, urllib.request, warnings, pathlib\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np, pandas as pd\n",
        "from tqdm import tqdm\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import models, transforms\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "\n",
        "# ----------------- Repro & perf -----------------\n",
        "SEED = 42\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED)\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "if DEVICE == \"cuda\":\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cuda.matmul.allow_tf32 = True\n",
        "print(\"✅ Device:\", DEVICE)\n",
        "\n",
        "# ----------------- Config -----------------\n",
        "TEXT_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "IMG_SIZE = 224\n",
        "IMG_PROJ = 384\n",
        "MLP_HID  = 512\n",
        "BATCH = 96 if DEVICE==\"cuda\" else 16\n",
        "LR = 3e-4\n",
        "EPOCHS = 6\n",
        "WEIGHT_DECAY = 1e-4\n",
        "EARLY_STOP = 2\n",
        "\n",
        "# ----------------- Load CSV -----------------\n",
        "if not os.path.exists(\"train.csv\"):\n",
        "    from google.colab import files\n",
        "    print(\"Please upload train.csv\")\n",
        "    uploaded = files.upload()\n",
        "    assert \"train.csv\" in uploaded\n",
        "\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "df.columns = [c.lower().strip() for c in df.columns]\n",
        "need = {\"sample_id\",\"catalog_content\",\"image_link\",\"price\"}\n",
        "if not need.issubset(df.columns):\n",
        "    raise ValueError(f\"Missing columns: {need - set(df.columns)}\")\n",
        "\n",
        "df[\"catalog_content\"] = df[\"catalog_content\"].astype(str).fillna(\"\").str.replace(\"\\x00\",\" \").str.strip()\n",
        "df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\")\n",
        "df = df[df[\"price\"]>0].dropna(subset=[\"catalog_content\",\"image_link\",\"price\"]).reset_index(drop=True)\n",
        "print(\"Rows:\", len(df))\n",
        "\n",
        "# ----------------- Split + Clip -----------------\n",
        "bins = pd.qcut(df[\"price\"], q=40, duplicates=\"drop\", labels=False)\n",
        "df_tr, df_va = train_test_split(df, test_size=0.2, random_state=SEED, stratify=bins)\n",
        "lo_clip, hi_clip = float(np.quantile(df_tr[\"price\"], 0.001)), float(np.quantile(df_tr[\"price\"], 0.999))\n",
        "df_tr[\"log_price\"] = np.log1p(df_tr[\"price\"])\n",
        "df_va[\"log_price\"] = np.log1p(df_va[\"price\"])\n",
        "print(f\"Train={len(df_tr)} | Valid={len(df_va)} | Clip=[{lo_clip:.2f},{hi_clip:.2f}]\")\n",
        "\n",
        "# ----------------- Tokenizer -----------------\n",
        "tok = AutoTokenizer.from_pretrained(TEXT_MODEL)\n",
        "MAX_LEN = 128\n",
        "\n",
        "# ----------------- Image caching -----------------\n",
        "CACHE = pathlib.Path(\"_img_cache\"); CACHE.mkdir(exist_ok=True)\n",
        "def url_to_path(u): return CACHE / (hashlib.md5(u.encode()).hexdigest()+\".jpg\")\n",
        "\n",
        "def fetch_image(u, timeout=8):\n",
        "    p = url_to_path(u)\n",
        "    if p.exists():\n",
        "        try: return Image.open(p).convert(\"RGB\")\n",
        "        except: p.unlink(missing_ok=True)\n",
        "    try:\n",
        "        req = urllib.request.Request(u, headers={\"User-Agent\":\"Mozilla/5.0\"})\n",
        "        with urllib.request.urlopen(req, timeout=timeout) as r: b = r.read()\n",
        "        img = Image.open(io.BytesIO(b)).convert(\"RGB\")\n",
        "        img.save(p, format=\"JPEG\", quality=85)\n",
        "        return img\n",
        "    except:\n",
        "        return Image.fromarray(np.full((IMG_SIZE,IMG_SIZE,3),255,np.uint8),\"RGB\")\n",
        "\n",
        "img_tfms = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),\n",
        "])\n",
        "\n",
        "# ----------------- Dataset -----------------\n",
        "class PriceDataset(Dataset):\n",
        "    def __init__(self, df): self.df=df.reset_index(drop=True)\n",
        "    def __len__(self): return len(self.df)\n",
        "    def __getitem__(self,i):\n",
        "        r=self.df.iloc[i]\n",
        "        t = tok(r[\"catalog_content\"],max_length=MAX_LEN,padding=\"max_length\",truncation=True,return_tensors=\"pt\")\n",
        "        img = img_tfms(fetch_image(r[\"image_link\"]))\n",
        "        y = torch.tensor(float(r[\"log_price\"]),dtype=torch.float32)\n",
        "        return t[\"input_ids\"].squeeze(0), t[\"attention_mask\"].squeeze(0), img, y\n",
        "\n",
        "dl_tr = DataLoader(PriceDataset(df_tr),batch_size=BATCH,shuffle=True,num_workers=4,pin_memory=True)\n",
        "dl_va = DataLoader(PriceDataset(df_va),batch_size=BATCH,shuffle=False,num_workers=4,pin_memory=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------- Model -----------------\n",
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, model_name=TEXT_MODEL):\n",
        "        super().__init__()\n",
        "        self.tx = AutoModel.from_pretrained(model_name)\n",
        "        self.out_dim = self.tx.config.hidden_size\n",
        "    def forward(self, ids, mask):\n",
        "        out = self.tx(input_ids=ids,attention_mask=mask,output_hidden_states=False)\n",
        "        pooled = out.last_hidden_state.mean(1)\n",
        "        return pooled\n",
        "\n",
        "class SwinTinyEncoder(nn.Module):\n",
        "    def __init__(self, out_dim=IMG_PROJ):\n",
        "        super().__init__()\n",
        "        net=models.swin_t(weights=models.Swin_T_Weights.IMAGENET1K_V1)\n",
        "        in_feat=net.head.in_features\n",
        "        net.head=nn.Identity()\n",
        "        self.backbone=net\n",
        "        self.head=nn.Sequential(nn.Linear(in_feat,out_dim),nn.ReLU(),nn.Dropout(0.2))\n",
        "        self.out_dim=out_dim\n",
        "    def forward(self,x):\n",
        "        return self.head(self.backbone(x))\n",
        "\n",
        "class PriceRegressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.txt=TextEncoder()\n",
        "        self.img=SwinTinyEncoder()\n",
        "        fused=self.txt.out_dim+self.img.out_dim\n",
        "        self.mlp=nn.Sequential(\n",
        "            nn.Linear(fused,MLP_HID),nn.ReLU(),nn.Dropout(0.2),\n",
        "            nn.Linear(MLP_HID,128),nn.ReLU(),nn.Dropout(0.2),\n",
        "            nn.Linear(128,1)\n",
        "        )\n",
        "    def forward(self,ids,mask,img):\n",
        "        t=self.txt(ids,mask); v=self.img(img)\n",
        "        return self.mlp(torch.cat([t,v],1)).squeeze(1)\n",
        "\n",
        "model=PriceRegressor().to(DEVICE)\n",
        "opt=torch.optim.AdamW(model.parameters(),lr=LR,weight_decay=WEIGHT_DECAY)\n",
        "scaler=torch.cuda.amp.GradScaler(enabled=(DEVICE==\"cuda\"))\n",
        "loss_fn=nn.SmoothL1Loss(beta=1.0)\n",
        "\n",
        "# ----------------- Metrics -----------------\n",
        "def smape_np(y_true,y_pred,eps=1e-8):\n",
        "    y_true,y_pred=np.expm1(y_true),np.expm1(y_pred)\n",
        "    return 100*np.mean(np.abs(y_pred-y_true)/(np.abs(y_true)+np.abs(y_pred)+eps))\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate():\n",
        "    model.eval(); preds,trues=[],[]\n",
        "    for ids,mask,img,y in dl_va:\n",
        "        ids,mask,img=ids.to(DEVICE),mask.to(DEVICE),img.to(DEVICE)\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
        "            pred=model(ids,mask,img).detach().cpu().numpy()\n",
        "        preds.append(pred); trues.append(y.numpy())\n",
        "    yp=np.concatenate(preds); yt=np.concatenate(trues)\n",
        "    yp=np.clip(np.expm1(yp),lo_clip,hi_clip); yt=np.expm1(yt)\n",
        "    return smape_np(np.log1p(yt),np.log1p(yp)),yt,yp\n",
        "\n",
        "# ----------------- Train -----------------\n",
        "best,pat=1e9,0\n",
        "for ep in range(1,EPOCHS+1):\n",
        "    model.train(); total=0; n=0; t0=time.time()\n",
        "    for ids,mask,img,y in tqdm(dl_tr,desc=f\"Epoch {ep:02d}\"):\n",
        "        ids,mask,img,y=ids.to(DEVICE),mask.to(DEVICE),img.to(DEVICE),y.to(DEVICE)\n",
        "        opt.zero_grad(set_to_none=True)\n",
        "        with torch.cuda.amp.autocast(enabled=(DEVICE==\"cuda\")):\n",
        "            pred=model(ids,mask,img)\n",
        "            loss=loss_fn(pred,y)\n",
        "        scaler.scale(loss).backward(); scaler.step(opt); scaler.update()\n",
        "        total+=loss.item()*len(y); n+=len(y)\n",
        "    sm,yt,yp=evaluate()\n",
        "    print(f\"Epoch {ep:02d} | TrainLoss {total/max(1,n):.4f} | Val SMAPE {sm:.2f} | {time.time()-t0:.1f}s\")\n",
        "    if sm<best-1e-3:\n",
        "        best,pat=sm,0\n",
        "        os.makedirs(\"artifacts\",exist_ok=True)\n",
        "        torch.save(model.state_dict(),\"artifacts/best_multimodal.pt\")\n",
        "    else:\n",
        "        pat+=1\n",
        "        if pat>=EARLY_STOP: print(\"Early stopping.\"); break\n",
        "\n",
        "# ----------------- Save artifacts -----------------\n",
        "with open(\"artifacts/config.json\",\"w\") as f:\n",
        "    json.dump({\n",
        "        \"text_model\":TEXT_MODEL,\"img_proj\":IMG_PROJ,\"mlp_hid\":MLP_HID,\n",
        "        \"max_len\":MAX_LEN,\"img_size\":IMG_SIZE,\n",
        "        \"lo_clip\":lo_clip,\"hi_clip\":hi_clip\n",
        "    },f,indent=2)\n",
        "print(\"\\n✅ Artifacts saved: best_multimodal.pt + config.json\")\n",
        "\n",
        "# ----------------- Final Eval -----------------\n",
        "state=torch.load(\"artifacts/best_multimodal.pt\",map_location=DEVICE)\n",
        "model.load_state_dict(state)\n",
        "model.eval()\n",
        "sm,yt,yp=evaluate()\n",
        "mae=mean_absolute_error(yt,yp); rmse=np.sqrt(mean_squared_error(yt,yp))\n",
        "print(f\"\\n=== Validation Summary ===\\nSMAPE={sm:.2f} | MAE={mae:.2f} | RMSE={rmse:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbthr_ANUcu6",
        "outputId": "a210c677-914f-4da9-9451-8f3b11bc48ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 01: 100%|██████████| 625/625 [36:52<00:00,  3.54s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | TrainLoss 0.3406 | Val SMAPE 29.01 | 2766.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 02: 100%|██████████| 625/625 [09:35<00:00,  1.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 02 | TrainLoss 0.2672 | Val SMAPE 29.05 | 719.8s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 03: 100%|██████████| 625/625 [09:26<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 03 | TrainLoss 0.2262 | Val SMAPE 26.57 | 709.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 04: 100%|██████████| 625/625 [09:30<00:00,  1.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 04 | TrainLoss 0.2045 | Val SMAPE 27.18 | 711.5s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 05: 100%|██████████| 625/625 [09:28<00:00,  1.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 05 | TrainLoss 0.1820 | Val SMAPE 26.06 | 712.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 06: 100%|██████████| 625/625 [09:16<00:00,  1.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 06 | TrainLoss 0.1626 | Val SMAPE 26.31 | 693.2s\n",
            "\n",
            "✅ Artifacts saved: best_multimodal.pt + config.json\n",
            "\n",
            "=== Validation Summary ===\n",
            "SMAPE=26.06 | MAE=11.55 | RMSE=23.68\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RK3MmrcTlfCJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}