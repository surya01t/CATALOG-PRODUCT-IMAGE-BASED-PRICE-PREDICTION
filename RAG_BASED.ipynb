{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afd5c942-19b3-49a3-b9b1-98e33b314db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf-keras in ./llmenv/lib/python3.12/site-packages (2.20.1)\n",
      "Requirement already satisfied: tensorflow<2.21,>=2.20 in ./llmenv/lib/python3.12/site-packages (from tf-keras) (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.4.0)\n",
      "Requirement already satisfied: packaging in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (25.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (6.32.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.32.4)\n",
      "Requirement already satisfied: setuptools in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (4.14.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.17.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (1.75.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.11.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (2.3.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./llmenv/lib/python3.12/site-packages (from tensorflow<2.21,>=2.20->tf-keras) (0.5.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./llmenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./llmenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./llmenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./llmenv/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow<2.21,>=2.20->tf-keras) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./llmenv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.9)\n",
      "Requirement already satisfied: pillow in ./llmenv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (11.3.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./llmenv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./llmenv/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.1.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./llmenv/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow<2.21,>=2.20->tf-keras) (0.45.1)\n",
      "Requirement already satisfied: rich in ./llmenv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (14.1.0)\n",
      "Requirement already satisfied: namex in ./llmenv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.0)\n",
      "Requirement already satisfied: optree in ./llmenv/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./llmenv/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow<2.21,>=2.20->tf-keras) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./llmenv/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./llmenv/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./llmenv/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow<2.21,>=2.20->tf-keras) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "773ebd4e-040c-44a2-b2f8-f32a3455c19a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-30 00:48:01.344221: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-30 00:48:01.396965: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 60000 | Valid: 15000\n",
      "Train price clip range: [0.640, 329.993]\n",
      "Encoding train embeddingsâ€¦\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19209bc5f504446be42d850d0dbe14d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ” RAG + Small LLM Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15000/15000 [22:15<00:00, 11.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " RAG + Small LLM (model: google/flan-t5-small, k=13)\n",
      "SMAPE (raw)    : 43.196\n",
      "SMAPE (scaled) : 43.196  (scale=1.0000)\n",
      "MAE            : 21.186\n",
      "RMSE           : 43.799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# RAG + Small LLM (Flan-T5 Small) â€” Zero-deps friendly\n",
    "# ============================\n",
    "\n",
    "import sys, subprocess, importlib, os, re, math, random, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- installer ---\n",
    "def ensure(pkg_spec, import_name=None):\n",
    "    name = (import_name or pkg_spec.split(\"==\")[0].split(\">=\")[0].split(\"[\")[0]).strip()\n",
    "    try:\n",
    "        importlib.import_module(name)\n",
    "    except Exception:\n",
    "        print(f\"Installing {pkg_spec} â€¦\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg_spec])\n",
    "\n",
    "# Core scientific stack\n",
    "ensure(\"numpy>=1.22\", \"numpy\")\n",
    "ensure(\"pandas>=1.5.0\", \"pandas\")\n",
    "ensure(\"scikit-learn>=1.1.0\", \"sklearn\")\n",
    "ensure(\"tqdm>=4.66.0\", \"tqdm\")\n",
    "\n",
    "# Torch (CPU by default; will use GPU if available)\n",
    "try:\n",
    "    import torch\n",
    "except Exception:\n",
    "    try:\n",
    "        # Generic install (pip resolves best wheel)\n",
    "        ensure(\"torch>=2.0.0\", \"torch\")\n",
    "    except Exception:\n",
    "        # CPU fallback index\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n",
    "                               \"-i\", \"https://download.pytorch.org/whl/cpu\", \"torch\"])\n",
    "import torch\n",
    "\n",
    "# NLP + embeddings\n",
    "ensure(\"transformers>=4.37.0\", \"transformers\")\n",
    "ensure(\"sentencepiece>=0.1.99\", \"sentencepiece\")\n",
    "ensure(\"accelerate>=0.27.0\", \"accelerate\")\n",
    "ensure(\"sentence-transformers>=2.2.2\", \"sentence_transformers\")\n",
    "\n",
    "# FAISS (optional). If it fails, we'll fallback to sklearn NearestNeighbors.\n",
    "USE_FAISS = True\n",
    "try:\n",
    "    import faiss # type: ignore\n",
    "except Exception:\n",
    "    try:\n",
    "        ensure(\"faiss-cpu>=1.7.4\", \"faiss\")\n",
    "        import faiss # type: ignore\n",
    "    except Exception:\n",
    "        print(\"faiss-cpu not available; falling back to sklearn NearestNeighbors.\")\n",
    "        USE_FAISS = False\n",
    "\n",
    "# ---- imports after install ----\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "MODEL_NAME = \"google/flan-t5-small\" # you can switch to \"google/t5-v1_1-small\" or \"google/byt5-small\"\n",
    "TOPK = 13 # CHANGED FROM 5 TO 13\n",
    "SNIP = 200      # chars per neighbor\n",
    "VAL_SIZE = 0.20\n",
    "MAX_PROMPT_TOKENS = 512\n",
    "MAX_NEW_TOKENS = 12\n",
    "\n",
    "# ---------------- Helpers ----------------\n",
    "_WS = re.compile(r\"\\s+\")\n",
    "def clean_text(s):\n",
    "    s = \"\" if not isinstance(s, str) else s.replace(\"\\x00\", \" \")\n",
    "    return _WS.sub(\" \", s).strip()\n",
    "\n",
    "def parse_price_str(s, default=0.0):\n",
    "    s = \"\" if s is None else str(s)\n",
    "    s = s.replace(\",\", \"\").strip()\n",
    "    m = re.search(r\"[-+]?\\d*\\.?\\d+\", s)\n",
    "    return float(m.group(0)) if m else default\n",
    "\n",
    "def smape(y_true, y_pred, eps=1e-8):\n",
    "    y_true = np.asarray(y_true, float); y_pred = np.asarray(y_pred, float)\n",
    "    return 100.0 * np.mean(np.abs(y_pred - y_true) / (np.abs(y_true) + np.abs(y_pred) + eps))\n",
    "\n",
    "def smape_calibrate(y_true, y_pred, lo=0.7, hi=1.3, n=121):\n",
    "    xs = np.linspace(lo, hi, int(n)); best_s, best_v = 1.0, 1e9\n",
    "    for s in xs:\n",
    "        v = smape(y_true, y_pred * s)\n",
    "        if v < best_v: best_s, best_v = float(s), float(v)\n",
    "    return best_s, best_v\n",
    "\n",
    "def clamp_and_clip(pred, lo_clip, hi_clip):\n",
    "    pred = np.asarray(pred, float)\n",
    "    pred[pred < 0.0] = 0.0\n",
    "    return np.clip(pred, lo_clip, hi_clip)\n",
    "\n",
    "def rmse_compat(y_true, y_pred):\n",
    "    try:\n",
    "        return float(mean_squared_error(y_true, y_pred, squared=False))\n",
    "    except TypeError:\n",
    "        return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n",
    "\n",
    "# ---------------- Load data ----------------\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "assert {\"catalog_content\", \"price\"}.issubset(df.columns), \"train.csv must contain catalog_content and price.\"\n",
    "\n",
    "df[\"catalog_content\"] = df[\"catalog_content\"].map(clean_text)\n",
    "df[\"price\"] = pd.to_numeric(df[\"price\"], errors=\"coerce\").fillna(0.0).astype(float)\n",
    "df[\"input_text\"] = df[\"catalog_content\"].astype(str)\n",
    "\n",
    "# Stratified 80/20 split by price quantiles\n",
    "q_bins = min(20, max(2, int(df[\"price\"].nunique() // 5)))\n",
    "bins = pd.qcut(df[\"price\"], q=q_bins, duplicates=\"drop\", labels=False)\n",
    "train_df, valid_df = train_test_split(df, test_size=VAL_SIZE, random_state=SEED, stratify=bins)\n",
    "print(f\"Train: {len(train_df)} | Valid: {len(valid_df)}\")\n",
    "\n",
    "# Robust clipping thresholds from train only\n",
    "lo_clip = float(np.quantile(train_df[\"price\"].values, 0.001))\n",
    "hi_clip = float(np.quantile(train_df[\"price\"].values, 0.999))\n",
    "print(f\"Train price clip range: [{lo_clip:.3f}, {hi_clip:.3f}]\")\n",
    "\n",
    "# ---------------- Build retriever ----------------\n",
    "print(\"Encoding train embeddingsâ€¦\")\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "train_texts = train_df[\"input_text\"].tolist()\n",
    "train_prices = train_df[\"price\"].values\n",
    "train_emb = embedder.encode(train_texts, convert_to_numpy=True, show_progress_bar=True, batch_size=64, normalize_embeddings=True)\n",
    "\n",
    "if USE_FAISS:\n",
    "    dim = train_emb.shape[1]\n",
    "    index = faiss.IndexFlatIP(dim) # cosine via inner product on normalized embeddings\n",
    "    index.add(train_emb)\n",
    "else:\n",
    "    # Fit a cosine NN index with sklearn (brute force)\n",
    "    nn = NearestNeighbors(n_neighbors=min(13, len(train_texts)), metric=\"cosine\", algorithm=\"brute\") # CHANGED FROM TOPK TO 13\n",
    "    nn.fit(train_emb)\n",
    "\n",
    "# ---------------- Load small LLM ----------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME).to(device)\n",
    "\n",
    "# ---------------- RAG prediction ----------------\n",
    "def rag_predict_prices(texts, k=13): # CHANGED FROM TOPK TO 13\n",
    "    preds = []\n",
    "    med_train = float(np.median(train_prices))\n",
    "    for txt in tqdm(texts, desc=\"ðŸ” RAG + Small LLM Predicting\"):\n",
    "        # retrieve indices of top-k similar train items\n",
    "        q_emb = embedder.encode([txt], convert_to_numpy=True, normalize_embeddings=True)\n",
    "        if USE_FAISS:\n",
    "            D, I = index.search(q_emb, k)\n",
    "            retrieved = train_df.iloc[I[0]]\n",
    "        else:\n",
    "            # sklearn cosine distance; lower is closer\n",
    "            D, I = nn.kneighbors(q_emb, n_neighbors=k, return_distance=True)\n",
    "            retrieved = train_df.iloc[I[0]]\n",
    "\n",
    "        # build examples text (avoid f-string backslash issue)\n",
    "        lines = []\n",
    "        for _, r in retrieved.iterrows():\n",
    "            snippet = str(r[\"input_text\"])[:SNIP].replace(\"\\n\", \" \")\n",
    "            lines.append(f\"Example: {snippet} ... => price={float(r['price']):.2f}\")\n",
    "        examples = \"\\n\".join(lines)\n",
    "\n",
    "        prompt = (\n",
    "            \"You are a pricing assistant. Using the examples of similar products and their prices, \"\n",
    "            \"predict the price for the new product.\\n\\n\"\n",
    "            f\"Similar examples:\\n{examples}\\n\\n\"\n",
    "            f\"New product:\\n{txt[:512]}\\n\\n\"\n",
    "            \"Answer with only a number in rupees, with two decimals (e.g., 129.99).\"\n",
    "        )\n",
    "\n",
    "        inp = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=MAX_PROMPT_TOKENS).to(device)\n",
    "        with torch.no_grad():\n",
    "            out_ids = model.generate(**inp, max_new_tokens=MAX_NEW_TOKENS, do_sample=False, num_beams=1)\n",
    "        pred_text = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "        preds.append(parse_price_str(pred_text, default=med_train))\n",
    "    return np.array(preds, dtype=float)\n",
    "\n",
    "# ---------------- Evaluate on validation ----------------\n",
    "y_true = valid_df[\"price\"].values.astype(float)\n",
    "y_pred = rag_predict_prices(valid_df[\"input_text\"].tolist(), k=13) # CHANGED FROM TOPK TO 13\n",
    "\n",
    "# post-process + calibration\n",
    "y_pred = clamp_and_clip(y_pred, lo_clip, hi_clip)\n",
    "scale, smape_scaled = smape_calibrate(y_true, y_pred, lo=0.7, hi=1.3, n=121)\n",
    "y_pred_scaled = y_pred * scale\n",
    "\n",
    "mae  = mean_absolute_error(y_true, y_pred_scaled)\n",
    "rmse = rmse_compat(y_true, y_pred_scaled)\n",
    "\n",
    "print(\"\\n RAG + Small LLM (model: %s, k=%d)\" % (MODEL_NAME, 13)) # CHANGED FROM TOPK TO 13\n",
    "print(f\"SMAPE (raw)    : {smape(y_true, y_pred):.3f}\")\n",
    "print(f\"SMAPE (scaled) : {smape(y_true, y_pred_scaled):.3f}  (scale={scale:.4f})\")\n",
    "print(f\"MAE            : {mae:.3f}\")\n",
    "print(f\"RMSE           : {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8436ba6-885c-426f-ae84-fd941816ae1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llmenv)",
   "language": "python",
   "name": "llmenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
